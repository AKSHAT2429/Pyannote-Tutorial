{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost there! To obtain the final speech regions, we need to apply a detection threshold.  \n",
    "For that, we rely on the voice activity detection pipeline whose hyper-parameters are set manually:\n",
    "- `onset=0.6`: mark region as `active` when probability goes above 0.6\n",
    "- `offset=0.4`: switch back to `inactive` when probability goes below 0.4\n",
    "- `min_duration_on=0.0`: remove `active` regions shorter than that many seconds\n",
    "- `min_duration_off=0.0`: fill `inactive` regions shorter than that many seconds\n",
    "\n",
    "\n",
    "More details about those hyper-parameters are provided in Figure 2 of [that paper](https://arxiv.org/abs/2104.04045)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.voice_activity_detection.VoiceActivityDetection at 0x1536d13f8c40>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model is your pretrained/finetuned/trained model name\n",
    "from pyannote.audio.pipelines import VoiceActivityDetection as VoiceActivityDetectionPipeline\n",
    "pipeline = VoiceActivityDetectionPipeline(segmentation=model)\n",
    "initial_params = {\"onset\": 0.6, \"offset\": 0.4, \n",
    "                  \"min_duration_on\": 0.0, \"min_duration_off\": 0.0}\n",
    "pipeline.instantiate(initial_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Timeline(uri=IS1009a, segments=[<Segment(23.0766, 23.8866)>, <Segment(25.6753, 26.9916)>, <Segment(28.2066, 29.8434)>, <Segment(54.9366, 82.2403)>, <Segment(83.3372, 119.99)>, <Segment(122.386, 146.753)>, <Segment(149.42, 162.599)>, <Segment(165.147, 167.054)>, <Segment(188.165, 188.435)>, <Segment(195.033, 202.39)>, <Segment(203.69, 218.236)>, <Segment(219.4, 227.298)>, <Segment(236.191, 238.368)>, <Segment(243.852, 245.135)>, <Segment(248.29, 256.036)>, <Segment(257.251, 257.791)>, <Segment(260.002, 272.557)>, <Segment(274.649, 285.871)>, <Segment(288.065, 293.853)>, <Segment(294.713, 297.818)>, <Segment(307.775, 314.474)>, <Segment(315.689, 318.457)>, <Segment(320.498, 327.907)>, <Segment(328.75, 333.172)>, <Segment(333.56, 336.378)>, <Segment(337.458, 339.23)>, <Segment(347.785, 350.148)>, <Segment(356.358, 364.998)>, <Segment(367.225, 376.085)>, <Segment(377.215, 381.721)>, <Segment(382.75, 393.685)>, <Segment(395.187, 399.946)>, <Segment(400.165, 400.925)>, <Segment(402.798, 412.72)>, <Segment(419.133, 427.604)>, <Segment(428.667, 435.046)>, <Segment(436.531, 449.423)>, <Segment(450.368, 496.741)>, <Segment(497.062, 506.883)>, <Segment(508.148, 661.812)>, <Segment(663.972, 677.371)>, <Segment(677.742, 684.053)>, <Segment(685.758, 750.828)>, <Segment(751.334, 757.679)>, <Segment(757.865, 757.983)>, <Segment(764.682, 766.555)>, <Segment(767.348, 776.022)>, <Segment(777.136, 793.994)>, <Segment(795.53, 806.06)>])>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(test_file).get_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH0AAABjCAYAAAAGhXxMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAALQElEQVR4nO3df6xkZ1kH8O9Dt6iJFZQtWrHJbZBiREOlK1INEatiwMQqVil/aCNEDaJRRE0gapdEE6lFoiZKVGrqj9hWabQSiqmxqZoIzW5tXVraWGIRlgKpSqVRF0of/5hz2cnl3rt3987eO+fM55NM9sz58c5z3vvMu2eeOedMdXcAAAAAmJan7HcAAAAAACyeog8AAADABCn6AAAAAEyQog8AAADABCn6AAAAAEzQgUU0cvDgwV5bW1tEUwAAAAAkOXr06KPdff6Zbr+Qos/a2lqOHDmyiKYAAAAASFJVH9rN9i7vAgAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJggRR8AAACACVL0AQAAAJigpSr6HD58eLKvN+V92ytT2qcz3ZdF9MF6G8vUnzuNZZliPl1jiX0sccKqWvb36NmMb6u2l71P9tLGvtA3y2fsf5Oxxw/zViWfq7t33cihQ4f6yJEjuw+mKouIZxlfb8r7tlemtE9nui+L6IP1NpapP3cayzLFfLrGEvtY4oRVtezv0bMZ31ZtL3uf7KWNfaFvls/Y/yZjjx/mjSWfq+podx860+2X6kwfAAAAABbjwH4HsFFV7XcIZ82U922v6MPF9sEY+3OMMY+NPgZ2Yz/GEOPW1vQNiyanYFyWruiz15dA7aUp79teGcPpdzuxm7/PIi7vWlRbi3I6/bEsMZ+uMb0nx9rHsArGMJaczcu79vo1x2azPtI3y2UM7+FTkVNMxRTejzuxVJd3XXPNNZN9vSnv216Z0j6d6b4sog/W21im/txpLMsU8+kaS+xjiRNW1bK/R89mfFu1vex9spc29oW+WT5j/5uMPX6Ytyr5vFQ3cgYAAABgxo2cAQAAAPg8ij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBBij4AAAAAE6ToAwAAADBB1d27b6TqU0ke3H04sNQOJnl0v4OAs0yeswrkOatAnrMK5Dmr4Lndfd6ZbnxgQUE82N2HFtQWLKWqOiLPmTp5ziqQ56wCec4qkOesgqo6spvtXd4FAAAAMEGKPgAAAAATtKiiz+8tqB1YZvKcVSDPWQXynFUgz1kF8pxVsKs8X8iNnAEAAABYLi7vAgAAAJggRR8AAACACTpl0aeqLqyqO6rq/qq6r6p+esPyN1RVV9XB4XlV1W9V1UNV9S9V9YKzFTwsylZ5XlWHq+p4Vd0zPF4+t80bhzx/sKq+a/+ih53Zbjyvqp+qqgeG+dfOzZfnjMo24/lNc2P5w1V1z9w28pxR2SbPL6mq9w55fqSqXjjMd3zO6GyT58+vqn+qqmNV9ddV9SVz2xjPGZWq+sKququq7h3y/M3D/Iuq6n1DPt9UVU8d5n/B8PyhYfnaqV7jwA7ieCLJG7r77qo6L8nRqrq9u++vqguTvDTJv8+t/7Ikzxke35Tkd4d/YZltmufDsrd193XzK1fV1ya5Ksnzknxlkr+tqou7+7N7GjWcnq3y/MuTXJHk+d19oqqemchzRmur45ZXrq9QVW9N8tgwLc8Zo63G82uTvLm7bxu+qLo2yUvi+Jxx2irP/yDJz3X3nVX16iQ/n+SXjOeM1Ikkl3f341V1bpJ/rKrbkvxsZp9Db6yqtyd5TWZj92uS/Fd3f3VVXZXkLUleuVXjyQ7O9OnuR7r77mH6U0k+kORZw+K3JfmFJPN3g74iyR/1zHuTPL2qLtj5PsPeO0Web+aKJDd294nu/rckDyV54dmPFM7cNnn+2iS/1t0nhmWfGDaR54zOqcbzqqokP5jkz4ZZ8pzR2SbPO8n6WQ9PS/LRYdrxOaOzTZ5fnOTvh9VuT/L9w7TxnNEZxuXHh6fnDo9OcnmSvxjm35Dke4fpK4bnGZZ/+3Bss6XTuqfPcOrQNyR5X1VdkeR4d9+7YbVnJfnw3POPZPsPz7BU5vN8mPWTw6nQ11fVlw7z5DmjtiHPL07y4uEU0Tur6huH1eQ5o7bJeJ4kL07y8e7+1+G5PGfUNuT5zyT59ar6cJLrkrxxWE2eM2ob8vy+zD74JskPJLlwmJbnjFJVnTNcdv6JzAqZH0zyye5+YlhlPpc/l+fD8seSPGO79ndc9KmqL07yzsz+M3kiyZuS/PJOt4cxmM/z7v7vzE6he3aSS5I8kuSt+xcdLMYmeX4gyZcleVFmp0jffKpvDGDZbZLn616Vk2f5wKhtkuevTfL67r4wyeuTvGM/44NF2CTPX53kJ6rqaJLzknx6P+OD3eruz3b3JUm+KrOz075mke3vqOgzXFv2ziR/2t23ZPYh+KIk91bVw0Nwd1fVVyQ5npPV1gzLji8yaDgbNsnzdPfHhzfhk0l+PydPEZXnjNJmeZ7Ztwe3DKeX3pXkySQHI88ZqS3yPFV1IMkrktw0t7o8Z5S2yPOrk6xP/3kctzByWxyfP9DdL+3uSzMr4n9wWF2eM2rd/ckkdyS5LLPLcNfvwTyfy5/L82H505L8x3bt7uTXuyqzbwk+0N2/MQRzrLuf2d1r3b2W2QeGF3T3x5LcmuSHh18JeFGSx7r7kdPZWdhrm+X5MH/+evfvS/L+YfrWJFcNd0+/KLMbI961V/HCmdgqz5P8ZZJvG9a5OMlTkzwaec4IbZPnSfIdSR7o7o/MzZPnjM42ef7RJN86TF+eZP0yRsfnjM42x+frPzjxlCS/mOTtwyLjOaNTVedX1dOH6S9K8p2Z3b/qjiRXDqtdneSvhulbh+cZlv9dd8/fY/nz7OTXu74lyQ8lOVYnf970Td397i3Wf3eSl2d246z/SfIjO3gN2G+b5nmSV1XVJZndTOvhJD+eJN19X1XdnOT+zC53fJ1fBmAEtsrz65NcX1Xvz+wU6auH/zzkOWO03XHLVdlwaZfxnJHaajz/0SS/OXz7+39JfmxY5vicMdoqz59TVa8bnt+S5A8T4zmjdUGSG6rqnMxOyrm5u99VVfcnubGqfiXJP+fk5brvSPLHVfVQkv/M7NhmW3WKohAAAAAAI3Rav94FAAAAwDgo+gAAAABMkKIPAAAAwAQp+gAAAABMkKIPAAAAwAQp+gAAo1VVz6iqe4bHx6rq+DD9eFX9zn7HBwCwn/xkOwAwCVV1OMnj3X3dfscCALAMnOkDAExOVb2kqt41TB+uqhuq6h+q6kNV9YqquraqjlXVe6rq3GG9S6vqzqo6WlV/U1UX7O9eAADsjqIPALAKnp3k8iTfk+RPktzR3V+f5H+TfPdQ+PntJFd296VJrk/yq/sVLADAIhzY7wAAAPbAbd39mao6luScJO8Z5h9LspbkuUm+LsntVZVhnUf2IU4AgIVR9AEAVsGJJOnuJ6vqM33ypoZPZnY8VEnu6+7L9itAAIBFc3kXAEDyYJLzq+qyJKmqc6vqefscEwDArij6AAArr7s/neTKJG+pqnuT3JPkm/c1KACAXfKT7QAAAAAT5EwfAAAAgAlS9AEAAACYIEUfAAAAgAlS9AEAAACYIEUfAAAAgAlS9AEAAACYIEUfAAAAgAn6f8GhC80slywjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Timeline(uri=IS1009a, segments=[<Segment(54.95, 60.85)>, <Segment(61.54, 80.83)>, <Segment(81.04, 82.05)>, <Segment(83.39, 86.94)>, <Segment(87.49, 88.59)>, <Segment(88.82, 89.69)>, <Segment(90.21, 90.52)>, <Segment(91.31, 107.4)>, <Segment(107.88, 118.17)>, <Segment(118.76, 119.05)>, <Segment(119.38, 119.91)>, <Segment(122.4, 132.39)>, <Segment(132.87, 146.77)>, <Segment(149.44, 162.32)>, <Segment(165.19, 166.99)>, <Segment(188.06, 188.34)>, <Segment(195.04, 195.27)>, <Segment(195.56, 195.82)>, <Segment(196.38, 202.4)>, <Segment(203.78, 218.2)>, <Segment(219.44, 222.12)>, <Segment(222.76, 227.27)>, <Segment(236.11, 238.38)>, <Segment(241.01, 242.5)>, <Segment(243.94, 245.45)>, <Segment(248.32, 251.04)>, <Segment(251.8, 252.7)>, <Segment(252.79, 254.69)>, <Segment(255.24, 257.74)>, <Segment(260.02, 272.52)>, <Segment(274.68, 275.95)>, <Segment(276.23, 279.86)>, <Segment(280.08, 285.51)>, <Segment(288.1, 297.75)>, <Segment(308.92, 310.65)>, <Segment(311.19, 318.45)>, <Segment(320.53, 327.5)>, <Segment(328.77, 333.36)>, <Segment(333.57, 335.49)>, <Segment(336.02, 336.43)>, <Segment(337.47, 339.63)>, <Segment(347.67, 349.78)>, <Segment(355.86, 364.82)>, <Segment(367.25, 375.93)>, <Segment(377.25, 386.09)>, <Segment(386.53, 387.02)>, <Segment(387.4, 393.64)>, <Segment(395.23, 398.51)>, <Segment(398.76, 399.29)>, <Segment(400.24, 400.93)>, <Segment(402.86, 412.67)>, <Segment(419.16, 427.58)>, <Segment(428.69, 434.99)>, <Segment(436.56, 449.23)>, <Segment(450.37, 495.68)>, <Segment(497.24, 502.27)>, <Segment(502.77, 503.46)>, <Segment(503.78, 506.79)>, <Segment(508.17, 551.13)>, <Segment(552.51, 565.64)>, <Segment(566.02, 581.45)>, <Segment(581.48, 637.63)>, <Segment(638.22, 641.25)>, <Segment(641.3, 661.77)>, <Segment(663.98, 665.07)>, <Segment(665.22, 683.95)>, <Segment(685.84, 703.98)>, <Segment(704.61, 711.13)>, <Segment(711.71, 715.68)>, <Segment(715.72, 744.62)>, <Segment(745.25, 750.08)>, <Segment(751.38, 758)>, <Segment(764.72, 775.95)>, <Segment(777.27, 787.09)>, <Segment(787.58, 793.95)>, <Segment(794.48, 794.68)>, <Segment(795.57, 795.88)>, <Segment(796.5, 797.81)>, <Segment(797.96, 803.68)>, <Segment(803.8, 805.72)>])>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks decent! Let's perform a proper evaluation by computing the [detection error rate](https://pyannote.github.io/pyannote-metrics/reference.html#detection) over the whole AMI test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection error rate = 7.3%\n"
     ]
    }
   ],
   "source": [
    "from pyannote.metrics.detection import DetectionErrorRate\n",
    "metric = DetectionErrorRate()\n",
    "\n",
    "for file in ami.test():\n",
    "    \n",
    "    # apply the voice activity detection pipeline\n",
    "    speech = pipeline(file)\n",
    "\n",
    "    # evaluate its output\n",
    "    _ = metric(\n",
    "        file['annotation'],     # this is the reference annotation\n",
    "        speech,                 # this is the hypothesized annotation\n",
    "        uem=file['annotated'])  # this is the part of the file that should be evaluated\n",
    "    \n",
    "# aggregate the performance over the whole test set\n",
    "detection_error_rate = abs(metric)\n",
    "print(f'Detection error rate = {detection_error_rate * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing pipeline hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While good enough, the hyper-parameters that we chose manually, we can try to optimize `onset` and `offset` on the development (a.k.a. validation) set to get better performance (and freeze the other two hyper-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.voice_activity_detection.VoiceActivityDetection at 0x1536d13f8c40>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.freeze({'min_duration_on': 0.0, 'min_duration_off': 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.pipeline import Optimizer\n",
    "\n",
    "optimizer = Optimizer(pipeline)\n",
    "optimizer.tune(list(ami.development()), \n",
    "               warm_start=initial_params, \n",
    "               n_iterations=20, \n",
    "               show_progress=False)\n",
    "\n",
    "optimized_params = optimizer.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go: better hyper-parameters that (should) lead to better results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'onset': 0.8020095763639215, 'offset': 0.5643079355945013, 'min_duration_on': 0.0, 'min_duration_off': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(optimized_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the voice activity detection pipeline with this new set of hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection error rate = 6.9%\n"
     ]
    }
   ],
   "source": [
    "optimized_pipeline = pipeline.instantiate(optimized_params)\n",
    "\n",
    "metric = DetectionErrorRate()\n",
    "\n",
    "for file in ami.test():\n",
    "    speech = optimized_pipeline(file)\n",
    "    _ = metric(file['annotation'], speech, uem=file['annotated'])\n",
    "    \n",
    "detection_error_rate = abs(metric)\n",
    "print(f'Detection error rate = {detection_error_rate * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ‰ Yeay! 5% relativement improvement simply by tuning the thresholds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
