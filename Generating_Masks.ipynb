{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOW TO GENERATE MASK (LABEL i.e. 0 or 1) FOR CLEAN AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(data, sample_rate=16000, min_utterance_length_ms=25, merge_dist_ms=32,\n",
    "             silence_value=0, silence_rtol=1e-1, silence_atol=1e-2):\n",
    "    \n",
    "\n",
    "    min_utterance_length = min_utterance_length_ms * sample_rate / 1000.0\n",
    "    merge_dist = merge_dist_ms * sample_rate / 1000.0\n",
    "\n",
    "    \n",
    "    if not isinstance(data, np.ndarray):\n",
    "        data = np.array(data)\n",
    "        assert len(data.shape) == 1\n",
    "    \n",
    "    \n",
    "    masked = (~ma.getmaskarray(ma.masked_values(data, silence_value, rtol=silence_rtol, atol=silence_atol))).astype(np.int8)\n",
    "    last_i = -1\n",
    "    \n",
    "    \n",
    "    for i in range(1, masked.shape[0]):\n",
    "        if masked[i - 1] == 1 and masked[i] == 0:\n",
    "            last_i = i - 1\n",
    "        elif masked[i - 1] == 0 and masked[i] == 1 and last_i > -1 and i - last_i <= merge_dist:\n",
    "            masked[last_i:i] = 1\n",
    "            last_i = -1\n",
    "            \n",
    "            \n",
    "    last_i = -1\n",
    "    \n",
    "    \n",
    "    for i in range(masked.shape[0]):\n",
    "        if last_i == -1 or (masked[i - 1] == 0 and masked[i] == 1):\n",
    "            last_i = i - 1\n",
    "        elif masked[i - 1] == 1 and masked[i] == 0 and i - last_i < min_utterance_length:\n",
    "            masked[last_i:i] = 0\n",
    "            last_i = -1\n",
    "            \n",
    "            \n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR CLEAN AUDIO\n",
    "\n",
    "import os\n",
    "# assign directory to clean audio\n",
    "directory = '/home/n2202857e/Documents/VAD/final_test_clean_mono'\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "    \n",
    "    \n",
    "    f = os.path.join(directory, filename)\n",
    "    saving_list = []\n",
    "    print(f)\n",
    "    \n",
    "    \n",
    "    for audiofilename in sorted(os.listdir(f)):\n",
    "        f1 = os.path.join(f, audiofilename)\n",
    "        print(f1)\n",
    "        waveform, sample_rate = torchaudio.load(f1)\n",
    "        np_arr = waveform.cpu().detach().numpy()\n",
    "        masked_array = get_mask(np_arr)\n",
    "        saving_list.append(masked_array[0])\n",
    "        \n",
    "        \n",
    "    #Pickling\n",
    "    with open(filename+'_CLEAN.txt', \"wb\") as fp:   \n",
    "        pickle.dump(saving_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOW TO GENERATE MASK (LABEL i.e. 0 or 1) FOR NOISY AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import torchaudio\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "from pyannote.audio import Pipeline\n",
    "import wave\n",
    "import contextlib\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_pretrained(\"pyannote/voice-activity-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign directory to noisy audio\n",
    "directory = '/home/n2202857e/Documents/VAD/final_test_noisy'\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "    \n",
    "    \n",
    "    f = os.path.join(directory, filename)\n",
    "    print(f)\n",
    "    saving_list = []\n",
    "    \n",
    "    \n",
    "    for audiofilename in sorted(os.listdir(f)):\n",
    "        f1 = os.path.join(f, audiofilename)\n",
    "        print(f1)\n",
    "        \n",
    "        \n",
    "        output = pipeline(f1)\n",
    "        \n",
    "        \n",
    "        with contextlib.closing(wave.open(f1,'r')) as f3:\n",
    "            frames = f3.getnframes()\n",
    "            rate = f3.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "        np_arr = numpy.zeros(frames,int)\n",
    "        \n",
    "        \n",
    "        for speech in output.get_timeline().support():\n",
    "            # active speech between speech.start and speech.end\n",
    "            np_arr[int(speech.start*16000):int(speech.end*16000)] = 1\n",
    "            \n",
    "            \n",
    "        saving_list.append(np_arr)\n",
    "        \n",
    "    #Pickling\n",
    "    with open(filename+'_NOISY.txt', \"wb\") as fp:   \n",
    "        pickle.dump(saving_list, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
